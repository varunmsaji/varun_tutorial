{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b782809-6e35-475a-bcd3-74b101b04bfc",
   "metadata": {},
   "source": [
    "retrieval augmented generation \n",
    "steps:\n",
    "load the document\n",
    "convert into vector store\n",
    "use llm to chat with the vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9751ae96-81bf-4662-b5cc-cf7e8c334da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/anaconda3/envs/genai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import google.generativeai as genai \n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "load_dotenv('/media/varun/Data/data science/main_files/.env')\n",
    "#set the environment variables\n",
    "os.environ['GOOGLE_API_KEY']=os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "#load the model \n",
    "model=genai.GenerativeModel('gemini-pro')\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "#call the model\n",
    "# result = llm.invoke(\"Write a ballad about LangChain\")\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23aa3f68-9699-40f8-9397-d3442e814421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not have the answer to your question from the provided context.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "#function to read the pdf document\n",
    "def pdf_read(pdf_filename):\n",
    "  text = \"\"\n",
    "  pdf_reader = PdfReader(pdf_filename)  # Use the single filename directly\n",
    "  for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "  return text\n",
    "\n",
    "text = pdf_read(\"2303.11366v4.pdf\")\n",
    "\n",
    "#chunking the text documents to smaller chunks\n",
    "def get_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "chunks = get_chunks(text)  \n",
    "\n",
    "#embedding the chunks\n",
    "embeddings = SpacyEmbeddings(model_name=\"en_core_web_sm\")\n",
    "\n",
    "#create a vector store\n",
    "def vector_store(chunks):\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_db\")\n",
    "    return vector_store\n",
    "vector=vector_store(chunks)    \n",
    "retriever = vector.as_retriever()\n",
    "# docs =retriever.get_relevant_documents('what is reinforcement learning')\n",
    "\n",
    "#create RAG chian \n",
    "template =\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question} \n",
    "\n",
    "Context: {context} \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain.invoke(\"what is reinforcement learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e406910-4b06-4fb3-9c9b-9866a08b07a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ee7cb3-c615-482d-a019-984671d72de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56984e6-a488-4c75-ad5c-008207f7f8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I love fruit juice'),\n",
       " Document(page_content='I like computers by Apple')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hybrid search \n",
    "#here we are giving 2 retrievers one with semantic search the normal one\n",
    "#other just a keyword search \n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "doc_list = [\n",
    "    \"I like apples\",\n",
    "    \"I like oranges\",\n",
    "    \"Apples and oranges are fruits\",\n",
    "    \"I like computers by Apple\",\n",
    "    \"I love fruit juice\"\n",
    "]\n",
    "\n",
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "#embedding the chunks\n",
    "embeddings = SpacyEmbeddings(model_name=\"en_core_web_sm\")\n",
    "\n",
    "faiss_vectorstore = FAISS.from_texts(doc_list, embeddings)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "faiss_retriever.get_relevant_documents(\"A green fruit\")\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever],\n",
    "                                       weights=[0.5, 0.5])\n",
    "docs = ensemble_retriever.get_relevant_documents(\"A green fruit\")\n",
    "docs = ensemble_retriever.get_relevant_documents(\"Apple Phones\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e123d-f873-4c52-8c54-19c245c4dd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
