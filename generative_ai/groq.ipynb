{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b5e66a-2773-48f8-b29c-13faff1dfcfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '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' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgsk_c7r46rKCnLJEadPjSQ0lWGdyb3FYX8wCucKEhUqcbNpCSMskgQ7W\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name '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' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69257880-7431-4277-a49e-77040ec75764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d1f069-3c99-40f0-9105-5a826043cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"mixtral-8x7b-32768\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2583f9c9-c2a5-42c9-bcd9-29874c3300dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, I\\'d be happy to explain!\\n\\nLLM stands for \"Low Latency Logging,\" which is a method of recording and transmitting data with minimal delay. Low latency LLMs are particularly important in time-sensitive applications, such as financial trading, online gaming, and real-time data processing.\\n\\nHere are some reasons why low latency LLMs are important:\\n\\n1. Faster Decision Making: In time-sensitive applications, every millisecond counts. Low latency LLMs ensure that data is transmitted and processed quickly, allowing for faster decision making. For example, in high-frequency trading, low latency LLMs can help traders make split-second decisions that can result in significant financial gains.\\n2. Improved User Experience: In online gaming and other real-time applications, low latency LLMs can help improve the user experience by reducing lag and ensuring smooth, responsive interactions. This is particularly important in multiplayer games, where even small delays can impact gameplay and lead to a poor user experience.\\n3. Increased Efficiency: Low latency LLMs can help increase efficiency by reducing the time it takes to transmit and process data. This can lead to cost savings and improved productivity, particularly in industries where data processing is a critical component of the business.\\n4. Enhanced Security: Low latency LLMs can also help enhance security by reducing the amount of time that data is vulnerable to attack. By transmitting data quickly and efficiently, low latency LLMs can help reduce the risk of data breaches and other security threats.\\n\\nOverall, low latency LLMs are an essential component of many time-sensitive applications. By ensuring fast, efficient, and secure data transmission, low latency LLMs can help businesses and individuals make better decisions, improve user experiences, increase efficiency, and enhance security.', response_metadata={'token_usage': {'completion_tokens': 390, 'prompt_tokens': 26, 'total_tokens': 416, 'completion_time': 0.604958265, 'prompt_time': 0.005208293, 'queue_time': None, 'total_time': 0.6101665580000001}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None}, id='run-c471d5d8-604d-4de7-a9e2-90035c986713-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"text\": \"Explain the importance of low latency LLMs.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60eff65-d24f-4dd9-8279-b676677c3811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silvery glow bright\n",
      "Luna's gentle light shines down\n",
      "Midnight's gentle queen"
     ]
    }
   ],
   "source": [
    "chat = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\",groq_api_key=\"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\")\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", \"Write a haiku about {topic}\")])\n",
    "chain = prompt | chat\n",
    "for chunk in chain.stream({\"topic\": \"The Moon\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e5b47-04d2-4d26-a932-39e48d3623e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
